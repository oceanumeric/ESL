{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Linear Regression of an Indicator Matrix\n",
    "\n",
    "Here each of the response categories are coded via an indicator variable.\n",
    "For example,\n",
    "\n",
    "$$Y_3 = [0, 0, 1, 0, 0]$$\n",
    "assuming we have 5 classes. This is also called _one-hot encoding_. \n",
    "\n",
    "Thus if $\\mathcal{G}$ has $K$ classes, there will be $K$ such indicators $Y_k$, $k=1,\\cdots,K$, with\n",
    "\n",
    "\\begin{equation}\n",
    "Y_k = 1 \\text{ if } G = k \\text{ else } 0.\n",
    "\\end{equation}\n",
    "\n",
    "These are collected together in a vector $Y=(Y_1,\\cdots,Y_k)$, and the $N$ training instances of these form an $N\\times K$ *indicator response matrix* $\\mathbf{Y}$, which is a matrix of $0$'s and $1$'s, with each row having a single $1$. \n",
    "\n",
    "For example,\n",
    "\n",
    "$$\n",
    "Y = \\begin{bmatrix} \n",
    "    1 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 & 0 \\\\\n",
    "     & & \\vdots & &  \\\\ \n",
    "    0 & 0 & 0 & 0 & 1\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We fit a linear regression model to each of the columns of $\\mathbf{Y}$ simultaneously, and the fit is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{Y}} = \\mathbf{X}\\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{X}\\hat{\\mathbf{B}}.\n",
    "\\end{equation}\n",
    "\n",
    "Note that we have a coefficient vector for each response columns $\\mathbf{y}_k$, and hence a $(p+1)\\times K$ coefficient matrix $\\hat{\\mathbf{B}} = \\left(\\mathbf{X}^T\\mathbf{X}\\right)^{-1}\\mathbf{X}^T\\mathbf{Y}$. Here $\\mathbf{X}$ is the model matrix with $p+1$ columns with a leading columns of $1$'s for the intercept.\n",
    "\n",
    "A new observation with input $x$ is classified as follows:\n",
    "* Compute the fitted output $\\hat{f}(x)^T = (1, x^T)^T\\hat{\\mathbf{B}}$, a $K$ vector.\n",
    "* Identify the largest component and classify accordingly:  \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{G}(x) = \\arg\\max_{k\\in\\mathcal{G}} \\hat{f}_k(x).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked class with the regression approach\n",
    "\n",
    "There is a serious problem with the regression approach when the number of class $K\\ge 3$, especially prevalent when $K$ is large. Because of the rigid nature of the regression model, classes can be *masked* by others. FIGURE 4.2 illustrates an extreme situation when $K=3$. The three classes are perfectly separated by linear decision boundaries, yet linear regression misses the middle class completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.108111402613945</td>\n",
       "      <td>-4.72571863413936</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.4771956650459828</td>\n",
       "      <td>-2.765558103380788</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.9031041492675986</td>\n",
       "      <td>-4.987922064070484</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.932767227473897</td>\n",
       "      <td>-4.592591785578464</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.931771172550313</td>\n",
       "      <td>-2.94463723320077</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  const                   x1                  x2    class\n",
       "0   1.0   -5.108111402613945   -4.72571863413936  class-1\n",
       "1   1.0  -3.4771956650459828  -2.765558103380788  class-1\n",
       "2   1.0  -3.9031041492675986  -4.987922064070484  class-1\n",
       "3   1.0   -3.932767227473897  -4.592591785578464  class-1\n",
       "4   1.0   -4.931771172550313   -2.94463723320077  class-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate three clusters\n",
    "size = 300\n",
    "cluster_means = {\n",
    "    'class-1': [-4, -4],\n",
    "    'class-2': [0, 0],\n",
    "    'class-3': [4, 4]\n",
    "}\n",
    "cluster_cov = np.eye(2)\n",
    "npdata = np.array([])  # sensitive to dtype\n",
    "nplabel = np.array([])\n",
    "np.random.seed(789)\n",
    "\n",
    "for l, v in cluster_means.items():\n",
    "    const = np.ones((size, 1))  # constant values\n",
    "    temp = np.random.multivariate_normal(\n",
    "            v, cluster_cov, size\n",
    "        )  # feature values, float type \n",
    "    label = np.array([l]*size).reshape(-1, 1)  # labels \n",
    "    temp = np.hstack((const, temp))  # stack together \n",
    "    npdata = np.append(\n",
    "        npdata, temp\n",
    "    ).reshape((-1, 3))\n",
    "    nplabel = np.append(\n",
    "        nplabel, label\n",
    "    ).reshape((-1, 1))  # string type \n",
    "\n",
    "sdata = pd.DataFrame(\n",
    "    np.hstack([npdata, nplabel]),\n",
    "    columns=['const', 'x1', 'x2', 'class']\n",
    ")\n",
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class-1</th>\n",
       "      <th>class-2</th>\n",
       "      <th>class-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class-1  class-2  class-3\n",
       "0        1        0        0\n",
       "1        1        0        0\n",
       "2        1        0        0\n",
       "3        1        0        0\n",
       "4        1        0        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ont-hot encoding\n",
    "y_mat = pd.get_dummies(sdata['class'])\n",
    "y_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3350334 ,  0.33335976,  0.33160684],\n",
       "       [-0.0611274 ,  0.00219793,  0.05892947],\n",
       "       [-0.05870027, -0.00227578,  0.06097605]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit linear regression\n",
    "x_mat = npdata[:, :3]\n",
    "beta = np.linalg.solve(x_mat.T @ x_mat, x_mat.T @ y_mat)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate coefficients\n",
    "y_est = x_mat @ beta\n",
    "y_est.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done:\n",
    "\n",
    "A new observation with input $x$ is classified as follows:\n",
    "* Compute the fitted output $\\hat{f}(x)^T = (1, x^T)^T\\hat{\\mathbf{B}}$, a $K$ vector.\n",
    "\n",
    "Now, we will:\n",
    "\n",
    "* Identify the largest component and classify accordingly:  \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{G}(x) = \\arg\\max_{k\\in\\mathcal{G}} \\hat{f}_k(x).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classified = y_est.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One rather formal justification is to view the regression as an estimate of conditional expectation. For the random variable $Y_k$, \n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{E}(Y_k|X=x) & = 0 \\cdot \\text{Pr}(G!=k|X=x) + 1 \\cdot \\text{Pr}(G=k|X=x) +\n",
    "                    0 \\cdot \\text{Pr}(G!=k|X=x) \\\\ \n",
    "                  & = \\text{Pr}(G=k|X=x),\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real issue is: How good an approximation to conditional expectation is the rather rigid linear regression model? Alternatively, are the $\\hat{f}_k(x)$ reasonable estimates of the posterior probabilities $\\text{Pr}(G=k|X=x)$, and more importantly, does this matter?\n",
    "\n",
    "It is quite straightforward to verify wheter the following condition will hold\n",
    "or not:,\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{k\\in\\mathcal{G}}\\hat{f}_k(x) = 1.\n",
    "\\end{equation}\n",
    "\n",
    "assuming the model has an intercept (or constant feature). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert whether row sum  == 1\n",
    "assert np.allclose(y_est.sum(axis=1), 1), 'Not all row sum == 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked class with the regression approach\n",
    "\n",
    "There is a serious problem with the regression approach when the number of class $K\\ge 3$, especially prevalent when $K$ is large. Because of the rigid nature of the regression model, classes can be *masked* by others. FIGURE 4.2 illustrates an extreme situation when $K=3$. The three classes are perfectly separated by linear decision boundaries, yet linear regression misses the middle class completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 4.2\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n",
    "axes[0].scatter(\n",
    "    sdata['x1'], sdata['x2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.108111402613945</td>\n",
       "      <td>-4.72571863413936</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.4771956650459828</td>\n",
       "      <td>-2.765558103380788</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.9031041492675986</td>\n",
       "      <td>-4.987922064070484</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.932767227473897</td>\n",
       "      <td>-4.592591785578464</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.931771172550313</td>\n",
       "      <td>-2.94463723320077</td>\n",
       "      <td>class-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  const                   x1                  x2    class\n",
       "0   1.0   -5.108111402613945   -4.72571863413936  class-1\n",
       "1   1.0  -3.4771956650459828  -2.765558103380788  class-1\n",
       "2   1.0  -3.9031041492675986  -4.987922064070484  class-1\n",
       "3   1.0   -3.932767227473897  -4.592591785578464  class-1\n",
       "4   1.0   -4.931771172550313   -2.94463723320077  class-1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e637eb1f212951f11bbcb105d1b42c01fcba4bbbd2a19d5c9065a96f28919fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
